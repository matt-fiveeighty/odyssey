---
phase: 07-scraper-enrichment-data-freshness
plan: 03
type: execute
wave: 3
depends_on: ["07-02"]
files_modified:
  - scripts/scrapers/co-draw-data.ts
  - scripts/scrapers/wy-draw-data.ts
  - scripts/scrapers/mt-draw-data.ts
  - scripts/scrapers/az-draw-data.ts
  - scripts/scrapers/nv-draw-data.ts
  - scripts/scrapers/nm-draw-data.ts
  - scripts/scrapers/id-draw-data.ts
  - scripts/scrapers/ks-draw-data.ts
  - scripts/scrapers/ak-draw-data.ts
autonomous: true

must_haves:
  truths:
    - "All 9 remaining active-state scrapers (CO, WY, MT, AZ, NV, NM, ID, KS, AK) have implemented scrapeDeadlines() returning structured deadline data"
    - "All 9 remaining active-state scrapers have implemented scrapeFees() returning structured fee data with NR tag costs and license fees"
    - "All 9 remaining active-state scrapers have implemented scrapeSeasons() returning season date ranges by species and weapon type"
    - "CO, WY, MT, AZ, NV, UT, OR, ID scrapers have implemented scrapeLeftoverTags() returning available leftover tag counts"
    - "All scrapers validate outputs through plausibility-guarded schemas before returning"
    - "All scrapers use cheerio extractTable() or parseHtml() instead of regex for any HTML parsing"
  artifacts:
    - path: "scripts/scrapers/co-draw-data.ts"
      provides: "Colorado scraper with deadlines, fees, seasons, leftover tags"
      exports: ["ColoradoScraper"]
    - path: "scripts/scrapers/wy-draw-data.ts"
      provides: "Wyoming scraper with deadlines, fees, seasons, leftover tags"
      exports: ["WyomingScraper"]
    - path: "scripts/scrapers/mt-draw-data.ts"
      provides: "Montana scraper with deadlines, fees, seasons, leftover tags"
      exports: ["MontanaScraper"]
    - path: "scripts/scrapers/az-draw-data.ts"
      provides: "Arizona scraper with deadlines, fees, seasons, leftover tags"
      exports: ["ArizonaScraper"]
    - path: "scripts/scrapers/nv-draw-data.ts"
      provides: "Nevada scraper with deadlines, fees, seasons, leftover tags"
      exports: ["NevadaScraper"]
    - path: "scripts/scrapers/nm-draw-data.ts"
      provides: "New Mexico scraper with deadlines, fees, seasons"
      exports: ["NewMexicoScraper"]
    - path: "scripts/scrapers/id-draw-data.ts"
      provides: "Idaho scraper with deadlines, fees, seasons, leftover tags"
      exports: ["IdahoScraper"]
    - path: "scripts/scrapers/ks-draw-data.ts"
      provides: "Kansas scraper with deadlines, fees, seasons"
      exports: ["KansasScraper"]
    - path: "scripts/scrapers/ak-draw-data.ts"
      provides: "Alaska scraper with deadlines, fees, seasons"
      exports: ["AlaskaScraper"]
  key_links:
    - from: "scripts/scrapers/co-draw-data.ts"
      to: "scripts/scrapers/base-scraper.ts"
      via: "Uses extractTable(), parseHtml() for HTML parsing"
      pattern: "this\\.extractTable|this\\.parseHtml"
    - from: "scripts/scrapers/co-draw-data.ts"
      to: "scripts/scrapers/schemas.ts"
      via: "Validates through PlausibleFeeSchema, PlausibleDeadlineSchema"
      pattern: "validateBatch.*Plausible"
---

<objective>
Implement scrapeDeadlines(), scrapeFees(), scrapeSeasons(), and scrapeLeftoverTags() for all 9 remaining active-state scrapers (CO, WY, MT, AZ, NV, NM, ID, KS, AK), following the OR/UT proof-of-concept pattern from 07-02.

Purpose: The roadmap requires SCRP-03 through SCRP-05 ("all active states" for deadlines, fees, seasons) and SCRP-09 (leftover tags for CO, WY, MT, AZ, NV, UT, OR, ID). This plan extends the patterns validated in OR/UT to the remaining states. Per research recommendation, states where automated scraping is impractical use structured hardcoded data with `source: "manual_verification"` notes, matching the pattern already used in OR/UT scrapeFees().

Output: All 9 remaining state scrapers enhanced with deadline, fee, season, and leftover tag methods. All outputs validated through plausibility schemas.
</objective>

<execution_context>
@/Users/mattramirez/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mattramirez/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-scraper-enrichment-data-freshness/07-02-SUMMARY.md

@scripts/scrapers/base-scraper.ts
@scripts/scrapers/schemas.ts
@scripts/scrapers/or-draw-data.ts
@scripts/scrapers/co-draw-data.ts
@.planning/phases/07-scraper-enrichment-data-freshness/07-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement deadlines, fees, seasons, leftover tags for CO, WY, MT, AZ, NV</name>
  <files>scripts/scrapers/co-draw-data.ts, scripts/scrapers/wy-draw-data.ts, scripts/scrapers/mt-draw-data.ts, scripts/scrapers/az-draw-data.ts, scripts/scrapers/nv-draw-data.ts</files>
  <action>
For each of the 5 high-priority state scrapers, implement the following methods by overriding the BaseScraper stubs. Follow the same dual approach used in OR/UT: (1) structured hardcoded data as primary source of truth for fees and well-known deadlines, (2) cheerio-based HTML scraping as supplemental/fallback.

**Pattern for each state scraper (apply to all 5):**

**scrapeDeadlines():**
- Emit structured deadline data for the current year based on known application windows. Each state has well-documented deadline dates published annually. Format:
  ```typescript
  { stateId: "CO", speciesId: "elk", deadlineType: "application_open", date: "2026-03-01", year: 2026 }
  { stateId: "CO", speciesId: "elk", deadlineType: "application_close", date: "2026-04-07", year: 2026 }
  { stateId: "CO", speciesId: "elk", deadlineType: "draw_results", date: "2026-05-31", year: 2026 }
  ```
- Supplement with cheerio-based scraping of each state's F&G deadline page where feasible.
- Validate through `PlausibleDeadlineSchema` before returning.

**scrapeFees():**
- Emit structured fee data following the exact pattern from OR/UT scrapeFees(): license-level fees first (NR hunting license, application fee, point/preference fee), then per-species NR tag costs, then per-species R tag costs.
- Use the fee amounts from the state F&G fee schedules (these are published annually and relatively stable).
- Supplement with cheerio scraping for any additional fees.
- Validate through `PlausibleFeeSchema` before returning.

**State-specific fee data (use these as the structured source of truth):**

Colorado (CPW):
- NR Hunting License: $101.49, App Fee: $10, Preference Point: $50
- NR Tag costs: elk $669.15, mule_deer $414.30, pronghorn $414.30, moose $2,597.12, bighorn_sheep $2,597.12, mountain_goat $2,597.12, black_bear $350.20, mountain_lion $350.20

Wyoming (WGF):
- NR Hunting License: $260, App Fee: $14, Preference Point: $50-$150 (varies by species)
- NR Tags: elk $652, mule_deer $412, pronghorn $266, moose $2,372, bighorn_sheep $2,372, mountain_goat $2,372, black_bear $352, bison $4,438

Montana (MFWP):
- NR Conservation License: $10, NR Big Game Combo: $1,054, App Fee: $5
- NR Tags: elk (included in combo), mule_deer (included), moose $1,502, bighorn_sheep $1,502, mountain_goat $1,502, black_bear $350, mountain_lion $320

Arizona (AZGFD):
- NR Hunting License: $160, App Fee: $13 per species
- NR Tags: elk $665, mule_deer $300, coues_deer $300, pronghorn $550, bighorn_sheep $2,000, black_bear $200, bison $3,000, mountain_lion $200

Nevada (NDOW):
- NR Hunting License: $142, App Fee: $10-15 per species
- NR Tags: elk $1,200, mule_deer $240, pronghorn $240, bighorn_sheep $1,200, mountain_goat $1,200, black_bear $180, mountain_lion $180

**scrapeSeasons():**
- Emit known season date ranges for major weapon types (archery, muzzleloader, rifle) by species.
- These vary by unit in most states, so emit statewide general season dates where applicable.
- Validate through `PlausibleSeasonSchema`.

**scrapeLeftoverTags():**
- For CO, WY, MT, AZ, NV: attempt to scrape the state's leftover tag page using cheerio.
- Each state publishes leftover/remaining tags after the draw results.
- Use `this.extractTable()` for HTML table pages, `this.fetchCsv()` for CSV downloads.
- Validate through `PlausibleLeftoverTagSchema`.

**For all 5 states, also:**
- Replace any existing regex HTML patterns with cheerio `extractTable()` or `parseHtml()`.
- Add fingerprinting on key pages (same pattern as OR/UT in 07-02).
- Import and use `validateBatch` with plausibility schemas.

**Important:** For fee data, use the structured approach (hardcoded verified data) as the primary path, with web scraping as supplemental. This matches the proven OR/UT pattern and produces reliable data even when state websites are down or redesigned.
  </action>
  <verify>
1. `npx tsc --noEmit` passes with no errors.
2. Each of the 5 scrapers has non-empty implementations of scrapeDeadlines(), scrapeFees(), scrapeSeasons(), scrapeLeftoverTags().
3. Each scraper imports and uses plausibility schemas from schemas.ts.
4. `grep -r 'validateBatch' scripts/scrapers/co-draw-data.ts scripts/scrapers/wy-draw-data.ts scripts/scrapers/mt-draw-data.ts scripts/scrapers/az-draw-data.ts scripts/scrapers/nv-draw-data.ts` returns matches for all 5 files.
  </verify>
  <done>
CO, WY, MT, AZ, NV scrapers have full implementations of scrapeDeadlines(), scrapeFees(), scrapeSeasons(), and scrapeLeftoverTags(). Fee data uses structured hardcoded values as primary source. All outputs validated through plausibility schemas. Any regex HTML parsing replaced with cheerio methods.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement deadlines, fees, seasons for NM, ID, KS, AK plus leftover tags for ID</name>
  <files>scripts/scrapers/nm-draw-data.ts, scripts/scrapers/id-draw-data.ts, scripts/scrapers/ks-draw-data.ts, scripts/scrapers/ak-draw-data.ts</files>
  <action>
Implement the same scraping methods for the remaining 4 active-state scrapers. These states are lower priority but still need deadline, fee, and season data for the app to show complete information.

**Follow the same pattern as Task 1** -- structured hardcoded fee data + cheerio-based supplemental scraping + plausibility validation.

**State-specific fee data:**

New Mexico (NMGF):
- NR Hunting License: $260, App Fee: $10 per species, Quality/Enhancement: $10
- NR Tags: elk $765, mule_deer $340, pronghorn $340, bighorn_sheep $3,115, barbary_sheep $340, black_bear $260, mountain_lion $290

Idaho (IDFG):
- NR Hunting License: $154.75, App Fee: $14.75
- NR Tags: elk $576.75, mule_deer $349.75, moose $2,283.50, bighorn_sheep $2,283.50, mountain_goat $2,283.50, pronghorn $308.50, black_bear $186.50, mountain_lion $186.50

Kansas (KDWP):
- NR Hunting License: $97.50, App Fee: $27.50
- NR Tags: mule_deer $392.50, whitetail $392.50, pronghorn $342.50, elk $400 (Fort Riley only)

Alaska (ADFG):
- NR Hunting License: $160, App Fee: varies by species
- NR Tags: moose $800, caribou $650, dall_sheep $850, grizzly $1,000, black_bear $450, mountain_goat $600, bison $900, muskox $2,200, elk $600, sitka_blacktail $300, wolf $60

**scrapeLeftoverTags():**
- Idaho: implement leftover tag scraping (IDFG publishes remaining tags). Use cheerio.
- NM, KS, AK: These states have different leftover tag systems that don't map cleanly to our model. Leave the base class stub (returns []) for now.

**For all 4 states:**
- Replace any regex HTML patterns with cheerio.
- Add plausibility validation.
- Add fingerprinting on key scrape pages.

**Important:** KS has a limited species list (deer, pronghorn, elk at Fort Riley). AK has the broadest species list (including dall_sheep, muskox, caribou, sitka_blacktail, wolf, grizzly) -- ensure species IDs match the constants in `species.ts`.
  </action>
  <verify>
1. `npx tsc --noEmit` passes with no errors.
2. Each of the 4 scrapers has non-empty implementations of scrapeDeadlines(), scrapeFees(), scrapeSeasons().
3. ID scraper has scrapeLeftoverTags() implementation.
4. All 4 scrapers import and use plausibility schemas.
5. `npx tsx scripts/scrapers/run-all.ts` runs all 15 scrapers without TypeScript compilation errors.
  </verify>
  <done>
NM, ID, KS, AK scrapers have full implementations of scrapeDeadlines(), scrapeFees(), scrapeSeasons(). ID has scrapeLeftoverTags(). All outputs validated through plausibility schemas. Species IDs match constants. All 15 scrapers compile and run via run-all.ts without errors.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. All 11 active-state scrapers (CO, WY, MT, NV, AZ, UT, NM, OR, ID, KS, AK) have implemented scrapeDeadlines(), scrapeFees(), scrapeSeasons()
3. 8 scrapers (CO, WY, MT, AZ, NV, UT, OR, ID) have implemented scrapeLeftoverTags()
4. All scrapers use plausibility-guarded schemas via validateBatch()
5. Zero regex HTML parsing patterns remain in any scraper file
6. `npx tsx scripts/scrapers/run-all.ts` compiles and runs (results depend on live website availability)
</verification>

<success_criteria>
- All 11 active-state scrapers produce structured deadline, fee, and season data
- 8 scrapers produce leftover tag data (SCRP-09 requirement: CO, WY, MT, AZ, NV, UT, OR, ID)
- Fee data uses the dual approach: structured hardcoded as primary, cheerio scraping as supplemental
- All outputs validated through plausibility-guarded Zod schemas
- The run-all.ts orchestrator runs all 15 scrapers without compilation errors
</success_criteria>

<output>
After completion, create `.planning/phases/07-scraper-enrichment-data-freshness/07-03-SUMMARY.md`
</output>
